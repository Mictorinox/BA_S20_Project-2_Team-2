application_train <- read.csv("/Users/rayz/Desktop/NYU/BA/project2/data/application_train_S20.csv")
head(application_train)
library(randomForest)
library(naniar)
#vis_miss(application_train, warn_large_data=FALSE)

missing_percentage<-apply(application_train, 2, function(col)sum(is.na(col))/length(col))
missing_percentage[missing_percentage>0.2]
missing_percentage_df<-as.data.frame(missing_percentage[missing_percentage>0.2])
index<-rownames(missing_percentage_df)
application_train_2<- application_train[,!(names(application_train) %in% index)]

correlation_percentage<-apply(application_train_2, 2, function(col)chisq.test(application_train_2$TARGET,col)$p.value)
correlation_percentage

correlation_percentage[correlation_percentage>0.05]
correlation_df<-as.data.frame(correlation_percentage[correlation_percentage>0.05])
index<-rownames(correlation_df)
index_2<-c(index,"TARGET")
application_train_3<- application_train_2[,(names(application_train_2) %in% index_2)]
colnames(application_train_3)

application_train_3$AMT_REQ_CREDIT_BUREAU_HOUR<-as.character(application_train_3$AMT_REQ_CREDIT_BUREAU_HOUR)
application_train_3$AMT_REQ_CREDIT_BUREAU_HOUR.new<-ifelse(  is.na(application_train_3$AMT_REQ_CREDIT_BUREAU_HOUR),"NULL",application_train_3$AMT_REQ_CREDIT_BUREAU_HOUR)
application_train_3$AMT_REQ_CREDIT_BUREAU_HOUR.new<-as.factor(application_train_3$AMT_REQ_CREDIT_BUREAU_HOUR.new)
table(application_train_3$AMT_REQ_CREDIT_BUREAU_HOUR.new)

application_train_3$AMT_REQ_CREDIT_BUREAU_DAY<-as.character(application_train_3$AMT_REQ_CREDIT_BUREAU_DAY)
application_train_3$AMT_REQ_CREDIT_BUREAU_DAY.new<-ifelse(  is.na(application_train_3$AMT_REQ_CREDIT_BUREAU_DAY),"NULL",application_train_3$AMT_REQ_CREDIT_BUREAU_DAY)
application_train_3$AMT_REQ_CREDIT_BUREAU_DAY.new<-as.factor(application_train_3$AMT_REQ_CREDIT_BUREAU_DAY.new)
table(application_train_3$AMT_REQ_CREDIT_BUREAU_DAY.new)

application_train_3$AMT_REQ_CREDIT_BUREAU_WEEK<-as.character(application_train_3$AMT_REQ_CREDIT_BUREAU_WEEK)
application_train_3$AMT_REQ_CREDIT_BUREAU_WEEK.new<-ifelse(  is.na(application_train_3$AMT_REQ_CREDIT_BUREAU_WEEK),"NULL",application_train_3$AMT_REQ_CREDIT_BUREAU_WEEK)
application_train_3$AMT_REQ_CREDIT_BUREAU_WEEK.new<-as.factor(application_train_3$AMT_REQ_CREDIT_BUREAU_WEEK.new)
table(application_train_3$AMT_REQ_CREDIT_BUREAU_WEEK.new)

to.remove <-c("AMT_REQ_CREDIT_BUREAU_HOUR","AMT_REQ_CREDIT_BUREAU_DAY","AMT_REQ_CREDIT_BUREAU_WEEK")
application_train_4 <- application_train_3[,-which(names(application_train_3) %in% to.remove)]
application_train_4  <- na.omit(application_train_4) 

#########################################################################################################
#under; over ; both sampling
application.df = application_train_4
library(ROSE)
application.under<-ovun.sample(TARGET~., data = application.df, method = "under", N= 60000)$data  
prop.table(table(application.under$TARGET))

application.over<-ovun.sample(TARGET~., data = application.df, method = "over", N= 350000)$data
prop.table(table(application.over$TARGET))

application.both = ovun.sample(TARGET~., data = application.df, method = "both", N= 350000)$data
prop.table(table(application.both$TARGET))

#randomly select 10% of the data and test the models
set.seed(123)
underindex <- sample(1:nrow(application.under),(.1)*nrow(application.under))  # technique to reduce dataset
application.under <- application.under [underindex, ] #reduce from 60000 to 6000

overindex = sample(1:nrow(application.over),(.1)*nrow(application.over))
application.over <- application.over [overindex, ] #reduce from 350000 to 35000

bothindex = sample(1:nrow(application.both),(.1)*nrow(application.both))
application.both <- application.both [bothindex, ] #reduce from 350000 to 35000
################################################################################################


####lerong yang:0.4
set.seed(1234)
application.df.balanced<-ovun.sample(TARGET~., data =  application.df, p=0.4, N= 20000)$data # this runs!
table(application.df.balanced$TARGET)
prop.table(table(application.df.balanced$TARGET))
application.balanced = application.df.balanced
####

namecol = names(application.balanced)[names(application.balanced) != 'SK_ID_CURR'] ############
outcomeName = 'TARGET'
predictorNames = names(application.balanced)[names(application.balanced) != outcomeName] 
predictorNames = names(application.df)[names(application.df) == namecol] 
print(predictorNames)

application.balanced$TARGET = as.factor(application.balanced$TARGET)

set.seed(666)  # setting seed to reproduce results of random sampling
split=(.70)
library (caret)
index = createDataPartition(application.balanced$TARGET, p=split, list=FALSE) # row indices for training data
train.df = application.balanced[ index,]  # model training data
test.df= application.balanced[ -index,]   # test data

################
## Model:rf1 ###
################

fitControl.rf1 = trainControl(method = "none")   # control parameters for training
rf1 = train(train.df[,predictorNames],train.df[,outcomeName],
            method='rf',
            trControl=fitControl.rf1)

rf1Imp<-varImp(rf1)  # computes variable importance for regression and classification models
rf1Imp
plot(rf1Imp)
rf1.predict<-predict(rf1,test.df[,predictorNames],type="raw")

actuals = as.factor(test.df$TARGET)
table(rf1.predict,actuals)
require(caret)
confusionMatrix(rf1.predict,actuals,positive = '1')

library(pROC)
rf1.probs <- predict(rf1,test.df[,predictorNames],type="prob") 
rf1.plot<-plot(roc(test.df$TARGET,rf1.probs[,2]))
auc(test.df$TARGET,rf1.probs[,2])
#0.6374 accuracy

################
## Model:rf2 ###
################
fitControl.rf2 = trainControl(method = "repeatedcv", number=10, repeats=3, search="random")   # control parameters for training
rf2 = train(train.df[,predictorNames],train.df[,outcomeName],
            method='rf',
            trControl=fitControl.rf2)

rf2Imp<-varImp(rf2)  # computes variable importance for regression and classification models
rf2Imp
plot(rf2Imp)
rf2.predict<-predict(rf2,test.df[,predictorNames],type="raw")

actuals = as.factor(test.df$TARGET)
table(rf2.predict,actuals)
require(caret)
confusionMatrix(rf2.predict,actuals,positive = '1')

library(pROC)
rf2.probs <- predict(rf2,test.df[,predictorNames],type="prob") 
rf2.plot<-plot(roc(test.df$TARGET,rf2.probs[,2]))
auc(test.df$TARGET,rf2.probs[,2])
#0.6484 accuracy






################################################################################################

# Algorithm Tune (tuneRF)
set.seed(seed)
bestmtry <- tuneRF(train.df[,predictorNames], train.df[,outcomeName], stepFactor=1.5, improve=1e-5, ntree=500)
print(bestmtry)
#mtry = 3 or 4 gives OOB error





